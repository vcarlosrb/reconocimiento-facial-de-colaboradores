{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Experimentación de la Redes Siamesas con la base datos \"Georgia Tech\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import imread\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy.random as rng\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementacion del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Funciones para inicializar parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segun el [artículo](http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf) sugiere las siguientes inicializaciones para las capas CNN:\n",
    " - Pesos con una media de 0.0 y una desviación estándar de 0.01\n",
    " - Bias con una media de 0.5 y una desviación estándar de 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(shape, dtype=None):\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bias(shape, dtype=None):\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Modelo Red Siamesa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitectura a bajo nivel de la red siames\n",
    "\n",
    "![siamese network_architecture](assets/siamese_network_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    # Se define la dimensión de los tensores para las dos entradas de imágenes\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # Red Neuronal Convolucional\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    # Generar los vectores caracteristicos para las dos imágenes\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Agregar la capa personalizada para calcular la diferencia absoluta entre los vectores caracteristicos de las dos imágenes\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Agregar la capa densa el cuál generará el puntaje de similitud\n",
    "    # Por medio de la función de activación sigmoid nos indicará con 0 si las dos imágenes son diferentes y 1 si son similares\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
    "    \n",
    "    # Conectar las entradas con la salida\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # Retornar el modelo\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. Resumen del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 105, 105, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 105, 105, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4096)         38960448    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_siamese_model((105, 105, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. Compilación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr = 0.00006)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importar data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se escogio el dataset de Georgia Tech debido a que brinda una gran cantidad de imagenes a colores y porque la posicion de los rostros varian considerablemente, lo que haria al modelo mas robusto. Este dataset contiene 750 imagenes en formato .jpg, pertenecientes a 50 personas. Se decidio agrupar las imagenes en 50 carpetas con 15 imagenes cada una. Ademas,se cambiaron las etiquetas dentro de cada carpeta a un numero entre 1 a 15. \n",
    "\n",
    "A partir de esta distribucion, se realizo un pequeño programa para escoger de manera aleatoria parejas iguales(imagenes dentro de la misma carpeta) y parejas sin similitud(imagenes en diferentes carpetas). Se escogieron 10000 parejas iguales y 10000 parejas sin similitud para mantener una correcta distribucion. Esta informacion se guardo como direciones de la imagen dentro de un DataFrame. Si las parejas sin similares el campo \"Igualdad\" es 1 y si son diferentes es 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=pd.read_csv(\"Imagenes_siamesas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Imagen1</th>\n",
       "      <th>Imagen2</th>\n",
       "      <th>Igualdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1/5.jpg</td>\n",
       "      <td>s1/6.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s1/7.jpg</td>\n",
       "      <td>s1/2.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s1/9.jpg</td>\n",
       "      <td>s1/10.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s1/3.jpg</td>\n",
       "      <td>s1/5.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s1/3.jpg</td>\n",
       "      <td>s1/10.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Imagen1    Imagen2  Igualdad\n",
       "0  s1/5.jpg   s1/6.jpg       1.0\n",
       "1  s1/7.jpg   s1/2.jpg       1.0\n",
       "2  s1/9.jpg  s1/10.jpg       1.0\n",
       "3  s1/3.jpg   s1/5.jpg       1.0\n",
       "4  s1/3.jpg  s1/10.jpg       1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Imagen1   20000 non-null  object \n",
      " 1   Imagen2   20000 non-null  object \n",
      " 2   Igualdad  20000 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "Data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Transformando a entero la variable de igualdad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[\"Igualdad\"]=Data[\"Igualdad\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Separando en train y validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo ideal es tener un train y test set que tengan una distribucion similar, por lo que se realizara una separacion estratificada con respecto a la columna \"Igualdad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_val=train_test_split(Data,test_size=0.15,stratify=Data[\"Igualdad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val=df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funciones de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path=\"data_georgia/cropped_faces/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Creando ImageDataGenerators para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando la funcion de ImageDataGenerator, creare dos nuevos generadores de imagenes que brinden dos imagenes de entrada al modelo segun la informacion brindada en el Dataframe que pasa a la funcion. \n",
    "\n",
    "Para los datos de entrada se realiza un poco de data augmentation al agregarle un angulo de rotacion de 5° y haciendo un maximo zoom de 10%. Esto no aplica para las imagenes de validacion.\n",
    "\n",
    "Información importante:\n",
    "- batch_size: 32\n",
    "- tamaño de la imagen: 160x160x3\n",
    "- rotation_range=5\n",
    "- zoom_range=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=5,\n",
    "                                   zoom_range=0.1)\n",
    "test_generator=ImageDataGenerator(rescale=1./255)\n",
    "val_generator=ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 =train_generator.flow_from_dataframe(dataframe=df_train,\n",
    "                                                 directory=images_path,\n",
    "                                                 x_col=X1,\n",
    "                                                 y_col=y,\n",
    "                                                  target_size=(105,105),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode=\"raw\",\n",
    "                                                  seed=42)\n",
    "    genX2 = train_generator.flow_from_dataframe(dataframe=df_train,\n",
    "                                                 directory=images_path,\n",
    "                                                 x_col=X2,\n",
    "                                                 y_col=y,\n",
    "                                                  target_size=(105,105),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode=\"raw\",\n",
    "                                                  seed=42)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_val_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 =val_generator.flow_from_dataframe(dataframe=df_val,\n",
    "                                                 directory=images_path,\n",
    "                                                 x_col=X1,\n",
    "                                                 y_col=y,\n",
    "                                                  target_size=(105,105),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode=\"raw\",\n",
    "                                                  seed=42)\n",
    "    genX2 = val_generator.flow_from_dataframe(dataframe=df_val,\n",
    "                                                 directory=images_path,\n",
    "                                                 x_col=X2,\n",
    "                                                 y_col=y,\n",
    "                                                  target_size=(105,105),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode=\"raw\",\n",
    "                                                  seed=42)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train_flow = gen_train_flow_for_two_inputs(\"Imagen1\", \"Imagen2\", \"Igualdad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_val_flow = gen_val_flow_for_two_inputs(\"Imagen1\", \"Imagen2\", \"Igualdad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento Modelo\n",
    "Para descargar el modelo entrenado ingresar a este enlace: [RS_georgia_db.h5](https://drive.google.com/file/d/1leTDVAZKUgVgrrnplric7jT10q8hKU_5/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint('RS_georgia_db.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "red_lr_plat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=7, verbose=1, mode='auto', cooldown=5, min_lr=0.0001)\n",
    "callbacks = [mc, red_lr_plat]\n",
    "history = model.fit_generator(gen_train_flow,\n",
    "                            steps_per_epoch = 532,\n",
    "                            validation_data = gen_val_flow,\n",
    "                            validation_steps = 94,\n",
    "                            epochs = 2,\n",
    "                            callbacks= callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('RS_georgia_db.h5') Guarda los pesos del ultimo epoch no recomendado si ya guardamos con model Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Adquirir los mejores parametros del modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se han guardado los mejores parametros con respecto al val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lead_weights('RS_georgia_db.h5')# Cargar los mejores pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generar predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este proyecto el test set serian las imagenes que vienen de la camara. Sin embargo, para probar la funcion se aplicara al validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Creando generador de imagenes para el test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_flow_for_two_inputs(X1, X2, y,df,dire):\n",
    "    genX1 =test_generator.flow_from_dataframe(dataframe=df,\n",
    "                                                 directory=dire,\n",
    "                                                 x_col=X1,\n",
    "                                                 y_col=y,\n",
    "                                                  target_size=(105,105),\n",
    "                                                  batch_size=1,\n",
    "                                                  class_mode=\"raw\",\n",
    "                                                  shuffle=False)\n",
    "    genX2 = test_generator.flow_from_dataframe(dataframe=df,\n",
    "                                                 directory=dire,\n",
    "                                                 x_col=X2,\n",
    "                                                 y_col=y,\n",
    "                                                  target_size=(105,105),\n",
    "                                                  batch_size=1,\n",
    "                                                  class_mode=\"raw\",\n",
    "                                                  shuffle=False)\n",
    "    while True:\n",
    "                X1i = genX1.next()\n",
    "                X2i = genX2.next()\n",
    "                yield [X1i[0], X2i[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(df,direccion_prediccion):\n",
    "    predictions=model.predict_generator(gen_test_flow_for_two_inputs(\"Imagen1\", \"Imagen2\", \"Imagen2\",\n",
    "                                                                            df,direccion_prediccion), steps = 1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Generando las predicciones por cada row del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_predicciones=[]\n",
    "\n",
    "for i in range(len(df_val)):\n",
    "\n",
    "    df_minitest=pd.DataFrame({\"Imagen1\":[df_val.loc[i,'Imagen1']],\"Imagen2\":[df_val.loc[i,'Imagen2']]})\n",
    "    tensor = get_prediction(df_minitest,images_path)\n",
    "    tensor=tensor.ravel()[0]\n",
    "\n",
    "    lista_predicciones.append(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57107264, 0.8720072, 0.96067595, 0.6933987, 0.12850149]\n"
     ]
    }
   ],
   "source": [
    "print(lista_predicciones[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
