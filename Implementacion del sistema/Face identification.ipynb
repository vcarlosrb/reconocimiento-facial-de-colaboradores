{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reconocimiento Facial de Colaboradores usando Red Convolucional Siamesa**\n",
    "\n",
    "### Proyecto Final de Técnicas Avanzadas de Data Mining y Sistemas Inteligentes\n",
    "Este proyecto permite el reconocimiento de rostros en tiempo real mediante el uso de una camara web.\n",
    "\n",
    "La solución continene los siguientes pasos principales:\n",
    "  - Detección de rostro.\n",
    "  - Reconocimiento de rostro.\n",
    "  \n",
    "Para el paso de detección de rostro nos apoyamos de la funcion de **OpenCV \"Haar Cascade\"**, posteriormente obtenemos el bounding box y ajustamos la imágen para que pueda ingresar al modelo. Para el paso de Reconocimiento de rostro de utilizó el **modelo pre-entrenado FaceNet** el cual nos brinda buenos vectores caracteristicos debido a que usa la **función de perdida en tripleta (triplet loss function)**.\n",
    "  \n",
    "## Autores\n",
    "* **Carlo Cano Gordillo**\n",
    "* **Oscar Moreno Feliz**\n",
    "* **Carlos Roca Bejar**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os.path\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "tfback._get_available_gpus = _get_available_gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Detección de rostro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Función Haarcascades por medio de camara web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\n",
    "        r'haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face():\n",
    "    save_loc = r''+folder_web_camera_image+'/temporal.jpg'\n",
    "    save_loc_cut_image = r''+folder_web_camera_image+'/temporal_cut.jpg'\n",
    "    capture_obj = cv2.VideoCapture(0)\n",
    "    # Establecemos el tamaño del marco de la cámara web\n",
    "    capture_obj.set(3, 640)\n",
    "    capture_obj.set(4, 480)\n",
    "    \n",
    "    if capture_obj.isOpened():\n",
    "        face_found = False\n",
    "        req_sec = 3\n",
    "        loop_start = time.time()\n",
    "        elapsed = 0\n",
    "\n",
    "        while(True):\n",
    "            curr_time = time.time()\n",
    "            elapsed = curr_time - loop_start # Contador para un máximo de 3 segundos para que detecte el rostro de la persona\n",
    "            if elapsed >= req_sec:\n",
    "                break\n",
    "\n",
    "            ret, frame = capture_obj.read()\n",
    "            frame = cv2.flip(frame, 1, 0)\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5) # Se detectan los rostros en el frame actual\n",
    "            if len(faces) > 1:\n",
    "                print(\"¡ERROR!, Sólo debe haber una persona en la foto.\")\n",
    "            else:\n",
    "                x, y, w, h = faces[0] # se obtiene las coordenadas del rostro de la persona\n",
    "                roi_color = frame[y:y+h, x:x+w]\n",
    "                cv2.imwrite(save_loc, roi_color) # recortamos la imagen del frame para obtener solo el rostro y lo almacenamos\n",
    "                cv2.rectangle(frame, (x-10, y-70), (x+w+20, y+h+40), (15, 175, 61), 4) # dibujamos el bounding box para que se muestre en la cámara web \n",
    "\n",
    "            cv2.imshow('frame', frame)\n",
    "            # para salir de la cámara web presionar la tecla 'q'\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        capture_obj.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"No se puede acceder a la cámara.\")\n",
    "\n",
    "    img = cv2.imread(save_loc)\n",
    "    if img is not None:\n",
    "        face_found = True\n",
    "    else:\n",
    "        face_found = False\n",
    "\n",
    "    return face_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Obtener vector característico de una imágen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding(image_path, model):\n",
    "    img1 = cv2.imread(image_path, 1)\n",
    "    img = img1[...,::-1]\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Funciones de procesamiento de imágen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_web_camera_image = 'saved_image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ini_user_database():\n",
    "    if os.path.exists('database/user_dict.pickle'):\n",
    "        with open('database/user_dict.pickle', 'rb') as handle:\n",
    "            user_db = pickle.load(handle)   \n",
    "    else:\n",
    "        user_db = {}\n",
    "        os.makedirs('database')\n",
    "        with open('database/user_dict.pickle', 'wb') as handle:\n",
    "            pickle.dump(user_db, handle, protocol=pickle.HIGHEST_PROTOCOL)   \n",
    "    return user_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_img_path(user_db, model, name, img_path):\n",
    "    if name not in user_db: \n",
    "        user_db[name] = img_to_encoding(img_path, model)\n",
    "        with open('database/user_dict.pickle', 'wb') as handle:\n",
    "                pickle.dump(user_db, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print('Usuario ' + name + ' agregado.')\n",
    "    else:\n",
    "        print('El usuario \"' + name + '\" ya ha sido registrado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(image_path):\n",
    "    img = cv2.imread(image_path, 1)\n",
    "    img = cv2.resize(img, (160, 160))\n",
    "    cv2.imwrite(image_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_webcam(user_db, FRmodel, name):\n",
    "    if name not in user_db: \n",
    "        face_found = detect_face()\n",
    "        if face_found:\n",
    "            temp_img = folder_web_camera_image + \"/temporal.jpg\"\n",
    "            resize_img(temp_img)\n",
    "            add_user_img_path(user_db, FRmodel, name, temp_img)\n",
    "        else:\n",
    "            print('No se ha encontrado un rostro en el frame.')\n",
    "    else:\n",
    "        print('El usuario \"' + name + '\" ya ha sido registrado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_user(user_db, name):\n",
    "    popped = user_db.pop(name, None)\n",
    "    \n",
    "    if popped is not None:\n",
    "        print('Usuario ' + name + ' eliminado.')\n",
    "        with open('database/user_dict.pickle', 'wb') as handle:\n",
    "                pickle.dump(user_db, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    elif popped == None:\n",
    "        print('Usuario no encontrado.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reconocimiento de rostro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_face(image_path, database, model, threshold=0.6):\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "\n",
    "    min_dist = 99999\n",
    "    for name in database:\n",
    "        dist = np.linalg.norm(np.subtract(database[name], encoding))\n",
    "        print(\"Nombre: \" + name + \", distancia: \" + str(dist))\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "\n",
    "    if min_dist > threshold:\n",
    "        print(\"Usuario no ha sido identificado.\")\n",
    "        identity = 'Persona desconocida'\n",
    "    else:\n",
    "        print(\"¡Hola \" + str(identity) + \"!\")\n",
    "\n",
    "    return min_dist, identity # Retornamos la persona con menos distancia en base a su vector caracteristico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_face_recognition_from_image(user_db, model, threshold, img_loc):\n",
    "    img = cv2.imread(img_loc, 1)\n",
    "    img = cv2.resize(img, (160, 160))\n",
    "    cv2.imwrite(img_loc, img)\n",
    "\n",
    "    find_face(img_loc, user_db, model, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Importación de modelo\n",
    "Previamente se debe descargar el modelo [facnet_keras.h5](https://drive.google.com/file/d/1wsJs5ZnhI7meqdOX6S9Indm9l1zmsisH/view?usp=sharing) y guardarlo dentro de la carpeta \"models\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de perdida de tripleta\n",
    "El objetivo de esta función de perdida es disminuir la distancia entre instancias de una misma clase y alejar aquellas de clases diferentes.\n",
    "\n",
    "![triplet_loss_function](assets/triplet_loss_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_pred, alpha = 0.2):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    pos_dist = tf.reduce_sum( tf.square(tf.subtract(y_pred[0], y_pred[1])) )\n",
    "    neg_dist = tf.reduce_sum( tf.square(tf.subtract(y_pred[0], y_pred[2])) )\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    \n",
    "    loss = tf.maximum(basic_loss, 0.0)\n",
    "   \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "FRmodel = load_model('models/facenet_keras.h5', custom_objects={'triplet_loss': triplet_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Uso del sistema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_db = ini_user_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Agregar nuevo usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuario Luciano Leon agregado.\n"
     ]
    }
   ],
   "source": [
    "add_user_webcam(user_db, FRmodel, \"Luciano Leon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Eliminar usuario (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuario Carlos eliminado.\n"
     ]
    }
   ],
   "source": [
    "delete_user(user_db, \"Carlos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reconocimiento facial de colaborador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_identification(user_db, model):\n",
    "    face_found = detect_face()\n",
    "    if face_found:\n",
    "        do_face_recognition_from_image(user_db, model, 7, folder_web_camera_image + \"/temporal.jpg\")\n",
    "    else:\n",
    "        print('No se ha encontrado un rostro en el frame.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre: Carlos Perez, distancia: 10.844667\n",
      "Nombre: Ricardo Bonifaz, distancia: 8.139328\n",
      "Nombre: Sergio Gonzales, distancia: 7.3957644\n",
      "Nombre: Franco Prado, distancia: 11.089435\n",
      "Nombre: Fiorela Quintanilla, distancia: 15.384703\n",
      "Nombre: Jesus Echegaray, distancia: 6.9111333\n",
      "Nombre: Cliff Zurita, distancia: 9.04925\n",
      "Nombre: Giancarlo Diaz, distancia: 13.694735\n",
      "Nombre: Luciano Leon, distancia: 6.676095\n",
      "¡Hola Luciano Leon!\n"
     ]
    }
   ],
   "source": [
    "face_identification(user_db, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Agregar usuarios de manera masiva\n",
    "Para esta funcionalidad se debe agregar una carpeta con el nombre de la persona dentro de la carpeta \"people\". Dentro de la carpeta con el nombre de la persona agregar la imágen de tamaño mayor a 500x500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_path = 'people/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El usuario \"Carlos Perez\" ya ha sido registrado.\n",
      "El usuario \"Ricardo Bonifaz\" ya ha sido registrado.\n",
      "El usuario \"Sergio Gonzales\" ya ha sido registrado.\n",
      "El usuario \"Franco Prado\" ya ha sido registrado.\n",
      "El usuario \"Fiorela Quintanilla\" ya ha sido registrado.\n",
      "El usuario \"Jesus Echegaray\" ya ha sido registrado.\n",
      "El usuario \"Cliff Zurita\" ya ha sido registrado.\n",
      "¡ERROR!, Sólo debe haber una persona en la foto.\n",
      "El usuario \"Giancarlo Diaz\" ya ha sido registrado.\n"
     ]
    }
   ],
   "source": [
    "for name in os.listdir(people_path):\n",
    "    name_path = os.path.join(people_path, name)\n",
    "    for filename in os.listdir(name_path):\n",
    "        image_path = os.path.join(name_path, filename)\n",
    "        image = cv2.imread(image_path, 1)\n",
    "        \n",
    "        frame = cv2.flip(image, 1, 0)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        if len(faces) > 1:\n",
    "            print(\"¡ERROR!, Sólo debe haber una persona en la foto.\")\n",
    "        else:\n",
    "            x, y, w, h = faces[0]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            resize_img = cv2.resize(roi_color, (160, 160))\n",
    "            temp_img = folder_web_camera_image + \"/temporal.jpg\"\n",
    "            cv2.imwrite(temp_img, resize_img)\n",
    "            add_user_img_path(user_db, FRmodel, name, temp_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reconocimiento facial en tiempo real**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Reconocimiento facil en tiempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_face_realtime(image_path, database, model, threshold):\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    registered = False\n",
    "    min_dist = 99999\n",
    "    identity = 'Persona desconocida'\n",
    "    for name in database:\n",
    "        dist = np.linalg.norm(np.subtract(database[name], encoding))\n",
    "        print(\"Nombre: \" + name + \", distancia: \" + str(dist))\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "\n",
    "    if min_dist > threshold:\n",
    "        registered = False\n",
    "    else:\n",
    "        registered = True\n",
    "    return min_dist, identity, registered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Detección de rostro en tiempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_realtime(database, model, threshold=6):\n",
    "    text = ''\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    save_loc = r''+folder_web_camera_image+'/temporal.jpg'\n",
    "    capture_obj = cv2.VideoCapture(0)\n",
    "    capture_obj.set(3, 640)\n",
    "    capture_obj.set(4, 480)\n",
    "    prev_time = time.time()\n",
    "    while(True):\n",
    "        ret, frame = capture_obj.read()\n",
    "        frame = cv2.flip(frame, 1, 0)\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi_color = frame[y-90:y+h+70, x-50:x+w+50]\n",
    "            cv2.imwrite(save_loc, roi_color)\n",
    "            curr_time = time.time()\n",
    "\n",
    "            if curr_time - prev_time >= 3:\n",
    "                img = cv2.imread(save_loc)\n",
    "                if img is not None:\n",
    "                    resize_img(save_loc)\n",
    "\n",
    "                    min_dist, identity, registered = find_face_realtime(\n",
    "                        save_loc, database, model, threshold)\n",
    "\n",
    "                    if min_dist <= threshold and registered:\n",
    "                        text = 'Bienvenido ' + identity\n",
    "                        print(text)\n",
    "                    else:\n",
    "                        text = 'Usuario desconocido'\n",
    "                        print('¡Usuario desconocido detectado!')\n",
    "                    print('Distancia minima:' + str(min_dist))\n",
    "                    print(\"--------------------------------------------\")\n",
    "                prev_time = time.time()\n",
    "\n",
    "            cv2.rectangle(frame, (x-10, y-70),\n",
    "                          (x+w+20, y+h+40), (15, 175, 61), 4)\n",
    "            cv2.putText(frame, text, (50, 50), font, 1, (158, 11, 40), 3)\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # close the webcam when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    capture_obj.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Ejecución de funciones\n",
    "Con el parámetro \"threshold\" se puede regular la distancia entre vectores caracteristicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre: Jesus, distancia: 8.0548935\n",
      "Nombre: Anel, distancia: 8.008589\n",
      "Nombre: Daniel, distancia: 9.617259\n",
      "Nombre: Gonzalo, distancia: 8.265307\n",
      "Nombre: Carlos, distancia: 4.2157307\n",
      "Nombre: Carlos Perez, distancia: 7.8946266\n",
      "Nombre: Ricardo Bonifaz, distancia: 6.012129\n",
      "Nombre: Sergio Gonzales, distancia: 6.5055523\n",
      "Nombre: Franco Prado, distancia: 7.8562565\n",
      "Nombre: Fiorela Quintanilla, distancia: 10.19094\n",
      "Nombre: Jesus Echegaray, distancia: 7.2403016\n",
      "Nombre: Cliff Zurita, distancia: 7.013948\n",
      "Nombre: Giancarlo Diaz, distancia: 8.403421\n",
      "Bienvenido Carlos\n",
      "Distancia minima:4.2157307\n",
      "--------------------------------------------\n",
      "Nombre: Jesus, distancia: 8.109145\n",
      "Nombre: Anel, distancia: 7.4207654\n",
      "Nombre: Daniel, distancia: 9.42279\n",
      "Nombre: Gonzalo, distancia: 7.971423\n",
      "Nombre: Carlos, distancia: 3.374651\n",
      "Nombre: Carlos Perez, distancia: 7.7983418\n",
      "Nombre: Ricardo Bonifaz, distancia: 6.090741\n",
      "Nombre: Sergio Gonzales, distancia: 6.380297\n",
      "Nombre: Franco Prado, distancia: 7.802237\n",
      "Nombre: Fiorela Quintanilla, distancia: 10.715634\n",
      "Nombre: Jesus Echegaray, distancia: 7.098583\n",
      "Nombre: Cliff Zurita, distancia: 6.858222\n",
      "Nombre: Giancarlo Diaz, distancia: 8.892977\n",
      "Bienvenido Carlos\n",
      "Distancia minima:3.374651\n",
      "--------------------------------------------\n",
      "Nombre: Jesus, distancia: 8.363175\n",
      "Nombre: Anel, distancia: 8.643649\n",
      "Nombre: Daniel, distancia: 10.1608305\n",
      "Nombre: Gonzalo, distancia: 8.101624\n",
      "Nombre: Carlos, distancia: 4.4404187\n",
      "Nombre: Carlos Perez, distancia: 7.8738127\n",
      "Nombre: Ricardo Bonifaz, distancia: 6.735991\n",
      "Nombre: Sergio Gonzales, distancia: 7.0312495\n",
      "Nombre: Franco Prado, distancia: 8.433567\n",
      "Nombre: Fiorela Quintanilla, distancia: 9.7398405\n",
      "Nombre: Jesus Echegaray, distancia: 8.396844\n",
      "Nombre: Cliff Zurita, distancia: 7.5958104\n",
      "Nombre: Giancarlo Diaz, distancia: 7.9967813\n",
      "Bienvenido Carlos\n",
      "Distancia minima:4.4404187\n",
      "--------------------------------------------\n",
      "Nombre: Jesus, distancia: 9.079395\n",
      "Nombre: Anel, distancia: 7.9653554\n",
      "Nombre: Daniel, distancia: 10.428618\n",
      "Nombre: Gonzalo, distancia: 9.2835655\n",
      "Nombre: Carlos, distancia: 4.718172\n",
      "Nombre: Carlos Perez, distancia: 8.237386\n",
      "Nombre: Ricardo Bonifaz, distancia: 5.2885714\n",
      "Nombre: Sergio Gonzales, distancia: 5.8799214\n",
      "Nombre: Franco Prado, distancia: 7.897892\n",
      "Nombre: Fiorela Quintanilla, distancia: 11.198244\n",
      "Nombre: Jesus Echegaray, distancia: 6.3498087\n",
      "Nombre: Cliff Zurita, distancia: 6.5383396\n",
      "Nombre: Giancarlo Diaz, distancia: 8.904782\n",
      "Bienvenido Carlos\n",
      "Distancia minima:4.718172\n",
      "--------------------------------------------\n",
      "Nombre: Jesus, distancia: 8.044517\n",
      "Nombre: Anel, distancia: 7.891475\n",
      "Nombre: Daniel, distancia: 9.68141\n",
      "Nombre: Gonzalo, distancia: 7.861016\n",
      "Nombre: Carlos, distancia: 4.4444957\n",
      "Nombre: Carlos Perez, distancia: 7.6610746\n",
      "Nombre: Ricardo Bonifaz, distancia: 6.510515\n",
      "Nombre: Sergio Gonzales, distancia: 6.6970377\n",
      "Nombre: Franco Prado, distancia: 8.1524935\n",
      "Nombre: Fiorela Quintanilla, distancia: 10.2581\n",
      "Nombre: Jesus Echegaray, distancia: 7.5637136\n",
      "Nombre: Cliff Zurita, distancia: 7.0550056\n",
      "Nombre: Giancarlo Diaz, distancia: 8.198032\n",
      "Bienvenido Carlos\n",
      "Distancia minima:4.4444957\n",
      "--------------------------------------------\n",
      "Nombre: Jesus, distancia: 8.139751\n",
      "Nombre: Anel, distancia: 7.8682923\n",
      "Nombre: Daniel, distancia: 9.694243\n",
      "Nombre: Gonzalo, distancia: 8.379449\n",
      "Nombre: Carlos, distancia: 3.7653217\n",
      "Nombre: Carlos Perez, distancia: 8.780963\n",
      "Nombre: Ricardo Bonifaz, distancia: 6.5500045\n",
      "Nombre: Sergio Gonzales, distancia: 6.9691505\n",
      "Nombre: Franco Prado, distancia: 8.749092\n",
      "Nombre: Fiorela Quintanilla, distancia: 11.494924\n",
      "Nombre: Jesus Echegaray, distancia: 7.783516\n",
      "Nombre: Cliff Zurita, distancia: 7.884437\n",
      "Nombre: Giancarlo Diaz, distancia: 9.012131\n",
      "Bienvenido Carlos\n",
      "Distancia minima:3.7653217\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "detect_face_realtime(user_db, FRmodel, threshold = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
